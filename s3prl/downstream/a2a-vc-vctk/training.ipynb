{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oWm0zXecPh6"
      },
      "source": [
        "# Intra-lingual A2A VC with S3PRL; S3PRL-VC\n",
        "[![Generic badge](https://img.shields.io/badge/GitHub-s3plr-9cf.svg)][github]\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)][notebook]\n",
        "\n",
        "Author: [tarepan]\n",
        "\n",
        "[github]:https://github.com/tarepan/s3prl\n",
        "[notebook]:https://colab.research.google.com/github/tarepan/s3prl/blob/master/s3prl/downstream/a2a-vc-vctk/training.ipynb\n",
        "[tarepan]:https://github.com/tarepan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFQivUIyZyYi"
      },
      "source": [
        "## Colab Check\n",
        "Check\n",
        "- Google Colaboratory runnning time\n",
        "- GPU type\n",
        "- Python version\n",
        "- CUDA version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cwyMoXOZ7e1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 \"sec)\"}'\n",
        "!head -n 1 /proc/driver/nvidia/gpus/**/information\n",
        "!python --version\n",
        "!pip show torch | sed '2!d'\n",
        "!/usr/local/cuda/bin/nvcc --version | sed '4!d'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K125Ein7VCwM"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wyVUJ9ram5l"
      },
      "source": [
        "Mount GoogleDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj11_OhkamFs",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJCLLQ_8cPiM"
      },
      "source": [
        "Clone the `tarepan/s3plr` repository and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ9fU-17Sdxb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/tarepan/s3prl.git\n",
        "\n",
        "%cd s3prl\n",
        "\n",
        "# !pip install \"torch==1.10.0\" -q      # Based on your PyTorch environment\n",
        "# !pip install \"torchaudio==0.10.0\" -q # Based on your PyTorch environment\n",
        "\n",
        "!apt-get install sox\n",
        "!pip install -e ./   # Repository itself\n",
        "# Need fairseq master (not latest stable version) & Patched Gambel-softmax\n",
        "!pip install \"git+https://github.com/tarepan/fairseq.git#egg=fairseq\"\n",
        "\n",
        "%cd ./s3prl/downstream/a2a-vc-vctk\n",
        "\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWG-TG7FbLML"
      },
      "source": [
        "Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7LUhy3PbNJA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Get pre-trained HiFi-GAN checkpoint archive and extract contents\n",
        "!./vocoder_download.sh ./\n",
        "\n",
        "# Get upstream's private mirror\n",
        "!mkdir -p /root/.cache/torch/hub\n",
        "!cp -r /content/gdrive/MyDrive/ML_data/s3prl_cache /root/.cache/torch/hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tiu2YKD2tVd"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptA8A-dhEgqZ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7ITg9-_b9Yd"
      },
      "source": [
        "Preprocessing is included in training scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# @./s3prl\n",
        "%cd ../..\n",
        "!mkdir -p /content/gdrive/MyDrive/ML_results/S3PRL_VC/a2a/vq_wav2vec_default_vctk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STcHETKK34nu",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "!python run_downstream.py \\\n",
        "    -u       vq_wav2vec \\\n",
        "    -d       a2a-vc-vctk \\\n",
        "    -m       train \\\n",
        "    --config downstream/a2a-vc-vctk/config_ar_taco2.yaml \\\n",
        "    -p       /content/gdrive/MyDrive/ML_results/S3PRL_VC/a2a/vq_wav2vec_default_vctk \\\n",
        "    # -o       \"config.downstream_expert.data.corpus.train.name=JVS,,config.downstream_expert.data.corpus.val.name=JVS\" \\\n",
        "    # -e       /content/gdrive/MyDrive/ML_results/S3PRL_VC/a2a_vc_vctk_default_vq_wav2vec/states-50000.ckpt \\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoG_q8lEdrHB"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDHR5EIAdwAe"
      },
      "source": [
        "Synthesize waveforms from already generated spectrograms and objectively evaluate them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oDbCYcm8y3E",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Waveforms will be properly synthesized and saved, but objective evaluation will failed.\n",
        "!./downstream/a2a-vc-vctk/decode.sh ./downstream/a2a-vc-vctk/hifigan_vctk /content/gdrive/MyDrive/ML_results/S3PRL_VC/a2a_vc_vctk_default_vq_wav2vec/50000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Tzv4AhWBPFW",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Only evaluation (not work now)\n",
        "# !python downstream/a2a-vc-vctk/evaluate.py --wavdir ./result/downstream/a2a_vc_vctk_default_vq_wav2vec/50001/hifigan_wav --samples 1 --task task1  --data_root ./downstream/a2a-vc-vctk/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKIasW5cTqhl",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# # Launch TensorBoard\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir gdrive/MyDrive/ML_results/S3PRL_VC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0O2DDaFlcPiX",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# # Usage stat\n",
        "# ## GPU\n",
        "# !nvidia-smi -l 3\n",
        "# ## CPU\n",
        "# !vmstat 5\n",
        "# !top"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!apt-get install sox\n",
        "!pip install \"git+https://github.com/tarepan/extorch.git\"\n",
        "!pip install \"git+https://github.com/tarepan/speechdatasety.git\"\n",
        "!pip install \"git+https://github.com/tarepan/speechcorpusy.git@main\"\n",
        "!pip install \"git+https://github.com/tarepan/fairseq.git#egg=fairseq\"\n",
        "!pip install \"git+https://github.com/tarepan/s3prl.git\"\n",
        "!pip install Resemblyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.cuda\n",
        "from s3prl import hub, downstream\n",
        "\n",
        "\n",
        "# Inputs/Config\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else device(\"cpu\")\n",
        "source_path  = \"./<path>/<to>/source.wav\"\n",
        "target_paths = [\"./<path>/<to>/target_1.wav\", \"./<path>/<to>/target_2.wav\"]\n",
        "source_wave = librosa.load(p, sr=16000)[0]\n",
        "target_waves = [librosa.load(p)[0] for p in target_paths]\n",
        "name_s2u = \"XXXXX\" # Upstream model name\n",
        "tacovc_path = \"/<path>/<to>/checkpoint.ckpt\"\n",
        "vocoder_path = \"/<path>/<to>/checkpoint.ckpt\"\n",
        "\n",
        "# Init\n",
        "wav2unit = getattr(hub, name_s2u)().to(device)\n",
        "tacovc = getattr(downstream.experts, \"a2a-vc-vctk\")().load_state_dict(torch.load(tacovc_path))\n",
        "vocoder = YourVocoder.from_pretrained(vocoder_path)\n",
        "\n",
        "# wave2unit:: List[(T_wave,)] -> [Batch=1, T_unit=T_mel, Feat]\n",
        "unit_series = wav2unit([torch.from_numpy(source_wave).to(device)])[\"feature_x\"]\n",
        "\n",
        "# unit2mel:: ([Batch=1, T_unit=T_mel, Feat], [Batch=1, Emb]) -> [Batch=1, T_mel, Freq] -> [T_mel, Freq]\n",
        "target_emb = tacovc.wavs2emb(target_waves)\n",
        "mel_by_tacovc, _ = tacovc.predict_step((unit_series, target_emb)) # Currently, both spec and spec_len are returned.\n",
        "mel_by_tacovc = torch.squeeze(mel_by_tacovc, 0)\n",
        "\n",
        "# mel2wave:: [T_mel, Freq] -> ([T_wave,], sampling_rate::int)\n",
        "mel_for_vocoder = your_mel_shape_conversion(mel_by_tacovc)\n",
        "o_wave, sr = vocoder.predict(mel_for_vocoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "training.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
